{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d97d0-d8aa-4834-b29f-d59a840afedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib as pl\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1666a-a43d-406f-ac6c-ddbcb9915481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialfusion.models.baseline_multi_ae import PairedAE  # your custom model class\n",
    "from spatialfusion.utils.baseline_ae_data_loader import load_and_preprocess_sample_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f57eb-00c8-4bcc-95d8-a1a5b2a12a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128  # Tune for your GPU/CPU capacity\n",
    "DEFAULT_LABEL = \"unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d80cdc-a8e6-4fae-a2bc-a2f06452e53c",
   "metadata": {},
   "source": [
    "# Define function to extract baseline embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813151fa-99d8-4cb6-b807-feb1eecc4b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings_baseline(model, sample_list,\n",
    "                                base_path, raw_path, used_genes,\n",
    "                                device=\"cpu\", image_size=224):\n",
    "    all_z1, all_z2, all_zjoint = [], [], []\n",
    "    all_celltypes, all_samples = [], []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(sample_list, desc=\"Samples\"):\n",
    "            try:\n",
    "                # Load data\n",
    "                img_tensor, gex_tensor, cell_ids = load_and_preprocess_sample_baseline(\n",
    "                    sample_name=sample,\n",
    "                    base_path=base_path,\n",
    "                    raw_path=raw_path,\n",
    "                    SOFT_UNION_GENE_LIST=used_genes,\n",
    "                    max_cells=100000,\n",
    "                    image_size=image_size\n",
    "                )\n",
    "\n",
    "                # Deduplicate cell_ids\n",
    "                cell_ids = pd.Index(cell_ids)\n",
    "                _, unique_idx = np.unique(cell_ids, return_index=True)\n",
    "                unique_idx = np.sort(unique_idx)\n",
    "                cell_ids_unique = cell_ids[unique_idx]\n",
    "                img_tensor = img_tensor[unique_idx]\n",
    "                gex_tensor = gex_tensor[unique_idx]\n",
    "\n",
    "                # Encode\n",
    "                dataset = TensorDataset(img_tensor.float(), gex_tensor.float())\n",
    "                loader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "                z1_list, z2_list = [], []\n",
    "                for x1, x2 in tqdm(loader, desc=f\"Encoding {sample}\", leave=False):\n",
    "                    x1, x2 = x1.to(device), x2.to(device)\n",
    "                    z1_list.append(model.encoder1(x1).detach().cpu())\n",
    "                    z2_list.append(model.encoder2(x2).detach().cpu())\n",
    "\n",
    "                z1 = torch.cat(z1_list).numpy()\n",
    "                z2 = torch.cat(z2_list).numpy()\n",
    "                z_joint = (z1 + z2) / 2\n",
    "\n",
    "                # Sanity check\n",
    "                if z1.shape[0] != len(cell_ids_unique):\n",
    "                    print(f\"[DEBUG] z1 shape: {z1.shape}, expected: {len(cell_ids_unique)}\")\n",
    "                    raise ValueError(\"Mismatch between z1 and cell_ids length\")\n",
    "\n",
    "                # Load labels\n",
    "                ct_path = pl.Path(base_path) / sample / \"celltypes.csv\"\n",
    "                adata_path = pl.Path(base_path) / sample / \"adata.h5ad\"\n",
    "                label_source = None\n",
    "\n",
    "                if ct_path.exists():\n",
    "                    label_source = pd.read_csv(ct_path, index_col=0).iloc[:, 0]\n",
    "                elif pl.Path(adata_path).exists():\n",
    "                    adata = sc.read_h5ad(adata_path)\n",
    "                    if \"celltypes\" in adata.obs.columns:\n",
    "                        label_source = adata.obs[\"celltypes\"]\n",
    "\n",
    "                # Align labels\n",
    "                if label_source is not None:\n",
    "                    label_source = label_source[~label_source.index.duplicated(keep=\"first\")]\n",
    "                    valid_ids = cell_ids_unique.intersection(label_source.index)\n",
    "\n",
    "                    if len(valid_ids) == 0:\n",
    "                        print(f\"[Warning] No label overlap for {sample}. Skipping.\")\n",
    "                        continue\n",
    "\n",
    "                    idx = cell_ids_unique.get_indexer(valid_ids)\n",
    "                    if np.any(idx < 0) or np.max(idx) >= len(z1):\n",
    "                        print(f\"[DEBUG] Sample {sample}\")\n",
    "                        print(f\"[DEBUG] idx min/max: {idx.min()} / {idx.max()}, z1 shape: {z1.shape}\")\n",
    "                        raise IndexError(\"Invalid index range after label alignment\")\n",
    "\n",
    "                    z1 = z1[idx]\n",
    "                    z2 = z2[idx]\n",
    "                    z_joint = z_joint[idx]\n",
    "                    labels = label_source.reindex(valid_ids).fillna(DEFAULT_LABEL).to_numpy()\n",
    "                    cell_ids_final = valid_ids\n",
    "                else:\n",
    "                    labels = np.full(len(cell_ids_unique), DEFAULT_LABEL, dtype=object)\n",
    "                    cell_ids_final = cell_ids_unique\n",
    "\n",
    "                # Store\n",
    "                all_z1.append(pd.DataFrame(z1, index=cell_ids_final))\n",
    "                all_z2.append(pd.DataFrame(z2, index=cell_ids_final))\n",
    "                all_zjoint.append(pd.DataFrame(z_joint, index=cell_ids_final))\n",
    "                all_celltypes.append(labels)\n",
    "                all_samples.append([sample] * len(cell_ids_final))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Skipping {sample} due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "    # Final concatenation\n",
    "    return (\n",
    "        pd.concat(all_z1),\n",
    "        pd.concat(all_z2),\n",
    "        pd.concat(all_zjoint),\n",
    "        np.concatenate(all_celltypes),\n",
    "        np.concatenate(all_samples)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9b577e-b667-486c-b8bf-d760f198b6c0",
   "metadata": {},
   "source": [
    "# Get embeddings for the baseline AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc18403-1a7f-4bf7-a602-a7a049600c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "cfg = OmegaConf.load(\"../../results/logs/baseline_ae/run_20251022-155824_28f7875f/config_28f7875f.yaml\")\n",
    "\n",
    "used_genes = pd.read_csv(\"../../results/logs/baseline_ae/run_20251022-155824_28f7875f/used_genes.txt\", header=None).values.ravel()\n",
    "\n",
    "d2_dim = len(used_genes)\n",
    "\n",
    "model = PairedAE(\n",
    "    d2_dim=d2_dim,  # or infer from data if not stored\n",
    "    latent_dim=cfg.training.latent_dim,\n",
    "    resnet_backbone=cfg.training.resnet_backbone,\n",
    "    freeze_resnet=cfg.training.freeze_resnet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e66e4-505f-426f-93d2-a05b0cdbb400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Load state dict ---\n",
    "checkpoint_path = \"../../results/checkpoint_dir_ae/baseline_ae/paired_model_28f7875f.pt\"\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=\"cpu\"))\n",
    "\n",
    "# --- Move to device ---\n",
    "device = \"cuda:5\"\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de141958-6cbb-4021-9cfe-bc1aa87210c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run embedding extraction\n",
    "z1_baseline, z2_baseline, z_joint_baseline, celltypes_baseline, samples_baseline = extract_embeddings_baseline(\n",
    "    model,\n",
    "    sample_list=cfg.dataset.test_samples,\n",
    "    base_path=cfg.dataset.datapath,\n",
    "    raw_path=cfg.dataset.rawpath,\n",
    "    used_genes=used_genes,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b87a85-21ed-4a76-9f34-685cd987b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialfusion.utils.embed_ae_utils import save_embeddings_separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215a8f16-55bd-4811-a943-1b73ffefc93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings_separately(\n",
    "    z1_baseline, z2_baseline, z_joint_baseline, celltypes_baseline, samples_baseline, mode='test',\n",
    "    out_dir=\"../../results/embeddings_ae/baseline-AE-test-output/\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f783071c-e448-40da-9499-99bba931faae",
   "metadata": {},
   "source": [
    "# Load embeddings from comparable multimodal AE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9669fa1c-3f3b-48b8-8536-7ca6de740f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back z_joint\n",
    "z_joint = pd.read_parquet(\"../../results/embeddings_ae/output-model-9e693874-test/z_joint_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7126e3-7041-48d5-8d73-74531615fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = pd.read_parquet(\"../../results/embeddings_ae/output-model-9e693874-test/z1_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2951607-9253-40b5-8aff-7f0cef15cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = pd.read_parquet(\"/../../results/embeddings_ae/output-model-9e693874-test/z2_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f84635-d7e7-42a8-9a3b-273c7c72ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "celltypes = []\n",
    "\n",
    "with h5py.File(\"../../results/embeddings_ae/output-model-9e693874-test/metadata_test.h5\", \"r\") as f:\n",
    "    celltypes = f[\"celltypes\"][:].astype(str)\n",
    "    samples = f[\"samples\"][:].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf1b4a-8901-4979-b1b3-3f4625b75896",
   "metadata": {},
   "source": [
    "# Compare performance of AEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd88a08-9d15-40c3-bdaa-4bcb49068675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_classification_lr(\n",
    "    z_joint_df: pd.DataFrame,\n",
    "    celltypes: np.ndarray,\n",
    "    n_splits: int = 4,\n",
    "    subsample_size: int | None = None,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate classification of celltypes from embeddings using Stratified K-fold\n",
    "    Logistic Regression. Optionally subsample first (stratified) and run\n",
    "    everything on that subset.\n",
    "\n",
    "    Args:\n",
    "        z_joint_df: DataFrame of embeddings (cells x features).\n",
    "        celltypes: Array-like of ground-truth cell type labels.\n",
    "        n_splits: Number of CV folds (may be reduced if some classes are tiny).\n",
    "        subsample_size: If set, run on a stratified subsample of this many rows.\n",
    "        random_state: Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        dict with average 'balanced_accuracy' and 'f1_macro'.\n",
    "    \"\"\"\n",
    "    # Filter out unknown/missing labels\n",
    "    valid = (celltypes != \"unknown\") & pd.notnull(celltypes)\n",
    "    X_full = z_joint_df.iloc[valid].to_numpy(copy=False)\n",
    "    y_full = np.asarray(celltypes)[valid]\n",
    "\n",
    "    # Need at least 2 classes\n",
    "    if len(np.unique(y_full)) < 2:\n",
    "        return {\"balanced_accuracy\": np.nan, \"f1_macro\": np.nan}\n",
    "\n",
    "    # ---- Optional stratified subsample ----\n",
    "    if subsample_size is not None and subsample_size < len(X_full):\n",
    "        n_keep = int(subsample_size)\n",
    "        sss = StratifiedShuffleSplit(\n",
    "            n_splits=1, train_size=n_keep, random_state=random_state\n",
    "        )\n",
    "        (keep_idx, _), = sss.split(X_full, y_full)\n",
    "        X = X_full[keep_idx]\n",
    "        y = y_full[keep_idx]\n",
    "    else:\n",
    "        X, y = X_full, y_full\n",
    "\n",
    "    # Encode labels after subsampling\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "\n",
    "    # Ensure we can do stratified K-fold: each class must have >= n_splits samples\n",
    "    _, counts = np.unique(y_encoded, return_counts=True)\n",
    "    min_class_count = int(counts.min())\n",
    "    if min_class_count < 2:\n",
    "        # Too few samples in at least one class to run CV\n",
    "        return {\"balanced_accuracy\": np.nan, \"f1_macro\": np.nan}\n",
    "\n",
    "    n_splits_eff = min(n_splits, min_class_count)\n",
    "    if n_splits_eff < n_splits:\n",
    "        print(f\"[info] Reducing n_splits from {n_splits} to {n_splits_eff} \"\n",
    "              f\"because the smallest class has only {min_class_count} samples.\")\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits_eff, shuffle=True, random_state=random_state)\n",
    "\n",
    "    bac_scores, f1_scores = [], []\n",
    "\n",
    "    for train_idx, test_idx in tqdm(skf.split(X, y_encoded), total=n_splits_eff):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]\n",
    "\n",
    "        clf = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LogisticRegression(\n",
    "                max_iter=1000,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=random_state,\n",
    "                solver=\"lbfgs\",\n",
    "                multi_class=\"auto\",\n",
    "            ),\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        bac_scores.append(balanced_accuracy_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average=\"macro\"))\n",
    "\n",
    "    return {\n",
    "        \"balanced_accuracy\": float(np.mean(bac_scores)),\n",
    "        \"f1_macro\": float(np.mean(f1_scores)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea36fb-4fc2-45f5-8de1-a7fac2a3585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_evaluation_AE = evaluate_classification_lr(z_joint_df=z_joint,\n",
    "                                celltypes=celltypes,\n",
    "                                n_splits=4, subsample_size=400_000,\n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4a9b2f-560b-46cc-846f-862665920f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_evaluation_AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99cc827-6b33-427b-aa2a-fe381f297426",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_evaluation_baseline = evaluate_classification_lr(z_joint_df=z_joint_baseline,\n",
    "                                celltypes=celltypes_baseline,\n",
    "                                n_splits=4, subsample_size=400_000,\n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6045489f-12ff-448a-b786-3ef2540d5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_evaluation_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415002f-d9a6-4f41-920e-fbed748f322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def batch_asw_fast(\n",
    "    embedding: np.ndarray,\n",
    "    batch_labels: np.ndarray,\n",
    "    celltype_labels: np.ndarray,\n",
    "    metric: str = 'euclidean',\n",
    "    max_cells: int = 20000,\n",
    "    scale: bool = True,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute batch average silhouette width (batch ASW) with stratified subsampling.\n",
    "    Designed for very large datasets (~millions of cells).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embedding : (n_cells, n_dims) array\n",
    "        Low-dimensional embedding of cells (e.g., PCA, UMAP, etc.).\n",
    "    batch_labels : (n_cells,) array-like\n",
    "        Batch assignment for each cell.\n",
    "    celltype_labels : (n_cells,) array-like\n",
    "        Cell-type or biological group assignment for each cell.\n",
    "    metric : str\n",
    "        Distance metric for silhouette_samples (default 'euclidean').\n",
    "    max_cells : int\n",
    "        Max number of cells to use for computing silhouettes.\n",
    "    scale : bool\n",
    "        Whether to scale as 1 - |silhouette| (so higher = better mixing).\n",
    "    random_state : int\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The batch ASW score (higher = better batch mixing).\n",
    "    \"\"\"\n",
    "\n",
    "    n_cells = embedding.shape[0]\n",
    "    if n_cells <= max_cells:\n",
    "        idx_keep = np.arange(n_cells)\n",
    "    else:\n",
    "        # --- Stratified subsampling: preserve cell-type Ã— batch proportions ---\n",
    "        df = pd.DataFrame({\n",
    "            \"celltype\": celltype_labels,\n",
    "            \"batch\": batch_labels\n",
    "        })\n",
    "        df[\"strata\"] = df[\"celltype\"].astype(str) + \"_\" + df[\"batch\"].astype(str)\n",
    "\n",
    "        # target number of samples per stratum, proportional to its frequency\n",
    "        np.random.seed(random_state)\n",
    "        strata_counts = df[\"strata\"].value_counts()\n",
    "        frac = min(1.0, max_cells / n_cells)\n",
    "        n_per_strata = np.maximum(1, (strata_counts * frac).astype(int))\n",
    "\n",
    "        idx_keep = (\n",
    "            df.groupby(\"strata\", group_keys=False)\n",
    "              .apply(lambda g: g.sample(n=min(len(g), n_per_strata[g.name]),\n",
    "                                        random_state=random_state))\n",
    "              .index.values\n",
    "        )\n",
    "\n",
    "    # Subset data\n",
    "    emb_sub = embedding[idx_keep]\n",
    "    batch_sub = np.asarray(batch_labels)[idx_keep]\n",
    "    celltype_sub = np.asarray(celltype_labels)[idx_keep]\n",
    "\n",
    "    # Encode labels for sklearn\n",
    "    batch_sub = LabelEncoder().fit_transform(batch_sub)\n",
    "    celltype_sub = np.asarray(celltype_sub)\n",
    "\n",
    "    # Compute silhouette for batches\n",
    "    sil_vals = silhouette_samples(emb_sub, batch_sub, metric=metric)\n",
    "\n",
    "    # Mean |silhouette| per cell type\n",
    "    df_sil = pd.DataFrame({\n",
    "        \"celltype\": celltype_sub,\n",
    "        \"silhouette\": sil_vals\n",
    "    })\n",
    "\n",
    "    per_ct = (\n",
    "        df_sil.groupby(\"celltype\")[\"silhouette\"]\n",
    "              .apply(lambda x: np.mean(np.abs(x)))\n",
    "              .values\n",
    "    )\n",
    "\n",
    "    avg_abs_sil = np.mean(per_ct)\n",
    "\n",
    "    return 1.0 - avg_abs_sil if scale else avg_abs_sil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0bf4a0-1fb3-4e5a-a0c9-2ea367bbdf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bASW = batch_asw_fast(\n",
    "    embedding=z_joint.values,\n",
    "    batch_labels=samples,\n",
    "    celltype_labels=celltypes,\n",
    "    metric='euclidean',\n",
    "     max_cells=100000,\n",
    "    scale=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d09097-f265-46ac-b550-9ccaaaca52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bASW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d0504-54c9-4b54-b793-456c81c23833",
   "metadata": {},
   "outputs": [],
   "source": [
    "bASW = batch_asw_fast(\n",
    "    embedding=z_joint_baseline.values,\n",
    "    batch_labels=samples_baseline,\n",
    "    celltype_labels=celltypes_baseline,\n",
    "    metric='euclidean',\n",
    "     max_cells=100000,\n",
    "    scale=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c700ed5b-77c4-4c07-9221-c2e4b8591b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "bASW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e0275-8156-4d46-be27-990d9c99935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def kbet(\n",
    "    embedding: np.ndarray,\n",
    "    batch_labels: np.ndarray,\n",
    "    k: int = 50,\n",
    "    max_cells: int = 20000,\n",
    "    alpha: float = 0.05,\n",
    "    random_state: int = 42,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute the kBET (k-nearest-neighbor Batch-Effect Test) score\n",
    "    following the implementation concept in the scIB benchmark.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    embedding : (n_cells, n_dims) array\n",
    "        Low-dimensional embedding of cells (e.g., PCA or UMAP).\n",
    "    batch_labels : (n_cells,) array-like\n",
    "        Batch assignment for each cell.\n",
    "    k : int\n",
    "        Number of neighbors for the local test (default 50).\n",
    "    max_cells : int\n",
    "        Max number of cells to subsample for runtime control.\n",
    "    alpha : float\n",
    "        Significance level for chi-squared test (default 0.05).\n",
    "    random_state : int\n",
    "        Random seed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        kBET acceptance rate = 1 - rejection_rate (higher = better mixing).\n",
    "    \"\"\"\n",
    "\n",
    "    n_cells = embedding.shape[0]\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    if n_cells > max_cells:\n",
    "        idx = rng.choice(n_cells, size=max_cells, replace=False)\n",
    "    else:\n",
    "        idx = np.arange(n_cells)\n",
    "\n",
    "    emb_sub = np.asarray(embedding)[idx]\n",
    "    batch_sub = np.asarray(batch_labels)[idx]\n",
    "\n",
    "    unique_batches, batch_counts = np.unique(batch_sub, return_counts=True)\n",
    "    batch_probs = batch_counts / batch_counts.sum()\n",
    "    n_batches = len(unique_batches)\n",
    "\n",
    "    # Build neighbor graph\n",
    "    nbrs = NearestNeighbors(n_neighbors=k + 1, metric='euclidean').fit(emb_sub)\n",
    "    knn_idx = nbrs.kneighbors(return_distance=False)[:, 1:]\n",
    "\n",
    "    # Expected batch counts in each neighborhood\n",
    "    expected = k * batch_probs\n",
    "    chi2_threshold = chi2.ppf(1 - alpha, df=n_batches - 1)\n",
    "\n",
    "    rejections = 0\n",
    "    for i in range(len(emb_sub)):\n",
    "        neighbor_batches = batch_sub[knn_idx[i]]\n",
    "        obs_counts = np.array([np.sum(neighbor_batches == b) for b in unique_batches])\n",
    "        chi2_stat = np.sum((obs_counts - expected) ** 2 / expected)\n",
    "        if chi2_stat > chi2_threshold:\n",
    "            rejections += 1\n",
    "\n",
    "    rejection_rate = rejections / len(emb_sub)\n",
    "    return 1.0 - rejection_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca2185f-fae5-4907-8e24-b8d878fb6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbet_ae = kbet(\n",
    "    embedding=z_joint.values,\n",
    "    batch_labels=samples,\n",
    "    k=50,\n",
    "    max_cells=100000,\n",
    "    alpha=0.05,\n",
    "    random_state=42,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bddd8ed-9dc1-4fa0-9267-5256ebcf720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbet_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24d90b-952a-4c5a-800c-fe7eb433a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbet_baseline = kbet(\n",
    "    embedding=z_joint_baseline.values,\n",
    "    batch_labels=samples_baseline,\n",
    "    k=50,\n",
    "    max_cells=100000,\n",
    "    alpha=0.05,\n",
    "    random_state=42,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a9689d-26a9-41b9-a190-018f6dac98b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbet_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74848d44-bb61-44da-94ae-dbac27c23bfd",
   "metadata": {},
   "source": [
    "# Plot latent spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60bfbcf-975d-49ba-b47b-ffd2c6fda41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def plot_embeddings(\n",
    "    z1, z2, z_joint, labels, samples, label_title,\n",
    "    palette=\"tab10\", seed=42, max_cells=500_000, savefig=None,\n",
    "):\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    df = pd.DataFrame({\"sample\": samples, \"label\": labels}, index=z1.index)\n",
    "    df[\"idx\"] = np.arange(len(df))\n",
    "    grouped = df.groupby(\"sample\")\n",
    "\n",
    "    # Determine how many cells per sample to keep\n",
    "    total_samples = len(grouped)\n",
    "    max_per_sample = max_cells // max(1, total_samples)\n",
    "\n",
    "    # Subsample per sample group\n",
    "    selected_indices = []\n",
    "    for _, group in grouped:\n",
    "        n = min(len(group), max_per_sample)\n",
    "        selected_indices.extend(rng.choice(group[\"idx\"].values, size=n, replace=False))\n",
    "\n",
    "    # Subset everything\n",
    "    z1 = z1.iloc[selected_indices]\n",
    "    z2 = z2.iloc[selected_indices]\n",
    "    z_joint = z_joint.iloc[selected_indices]\n",
    "    labels = np.array(labels)[selected_indices]\n",
    "    samples = np.array(samples)[selected_indices]\n",
    "\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    z1_pca = pca.fit_transform(z1.values)\n",
    "    z2_pca = pca.fit_transform(z2.values)\n",
    "    z_joint_pca = pca.fit_transform(z_joint.values)\n",
    "\n",
    "    # Shuffle for plot order\n",
    "    perm = rng.permutation(len(labels))\n",
    "    z1_pca = z1_pca[perm]\n",
    "    z2_pca = z2_pca[perm]\n",
    "    z_joint_pca = z_joint_pca[perm]\n",
    "    labels = labels[perm]\n",
    "\n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    point_size = 5  # keep a single source of truth for both scatter and legend markers\n",
    "\n",
    "    def _strip_spines(ax):\n",
    "        # Remove ALL spines (no plot borders)\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "        # No ticks and equal aspect\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "    def plot_scatter(ax, emb, title, show_legend=False):\n",
    "        sns.scatterplot(\n",
    "            x=emb[:, 0],\n",
    "            y=emb[:, 1],\n",
    "            hue=labels,\n",
    "            palette=palette,\n",
    "            s=point_size,\n",
    "            ax=ax,\n",
    "            linewidth=0,\n",
    "            alpha=0.8,\n",
    "            legend=\"full\" if show_legend else False,\n",
    "        )\n",
    "        #ax.set_title(title, fontsize=25)\n",
    "        ax.set_title('', fontsize=25)\n",
    "        _strip_spines(ax)\n",
    "\n",
    "    plot_scatter(axes[0], z1_pca, \"H&E (PCA)\")\n",
    "    plot_scatter(axes[1], z2_pca, \"RNA (PCA)\")\n",
    "    plot_scatter(axes[2], z_joint_pca, \"Joint (PCA)\", show_legend=True)\n",
    "\n",
    "    # Extract and remove subplot legend\n",
    "    handles, labels_ = axes[2].get_legend_handles_labels()\n",
    "    if axes[2].legend_ is not None:\n",
    "        axes[2].legend_.remove()\n",
    "\n",
    "    # Make legend marker sizes match the scatter point size\n",
    "    # (handles from seaborn are PathCollections for the color items)\n",
    "    for h in handles:\n",
    "        if hasattr(h, \"set_sizes\"):\n",
    "            h.set_sizes([point_size])  # one marker per legend entry\n",
    "\n",
    "    # Add shared figure legend (text size follows rcParams; markers already matched)\n",
    "    fig.legend(\n",
    "        handles,\n",
    "        labels_,\n",
    "        loc=\"center left\",\n",
    "        bbox_to_anchor=(1.01, 0.5),\n",
    "        title=label_title,\n",
    "        scatterpoints=1,     # one marker per legend entry\n",
    "        markerscale=10,     # keep scale = 1 to respect set_sizes above\n",
    "        frameon=False,       # optional: no border around the legend\n",
    "        fontsize=16,        # control legend text size here\n",
    "        title_fontsize=18,\n",
    "    )\n",
    "\n",
    "    if savefig is not None:\n",
    "        fig.savefig(savefig, dpi=200, bbox_inches='tight')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e443e5-1f5f-4b42-90ad-3d9be3ac4140",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85470f24-64a3-4067-999d-532edfeaf483",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_batch = sns.color_palette('muted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a03f52-6b97-4cbf-aeb7-247294691306",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_palette = {ct: palette[i] for i, ct in enumerate(np.unique(celltypes))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b02a79-9802-493a-9d9a-eda5b93ef7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_palette = {btc: palette_batch[i] for i, btc in enumerate(np.unique(samples))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597931a5-e3a9-4cde-a1fb-88899ac86cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(z1, z2, z_joint, celltypes, samples, label_title=\"Cell Type\", max_cells=1000000, palette=ct_palette,\n",
    "                savefig='../../../SpatialFusion/results/figures_Fig1/ae_celltype_scatter.png')\n",
    "plot_embeddings(z1, z2, z_joint, samples, samples, label_title=\"Sample\", max_cells=1000000, palette=batch_palette,\n",
    "                savefig='../../../SpatialFusion/results/figures_Fig1/ae_batch_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505fe52b-0e4e-4d16-8ce7-dfb9438fe48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(z1_baseline, z2_baseline, z_joint_baseline, celltypes_baseline, samples_baseline,\n",
    "                label_title=\"Cell Type\", max_cells=1000000, palette=ct_palette,\n",
    "                savefig='../../results/figures_Fig1/baseline_ae_celltype_scatter.png')\n",
    "plot_embeddings(z1_baseline, z2_baseline, z_joint_baseline, samples_baseline, samples_baseline,\n",
    "                label_title=\"Sample\", max_cells=1000000, palette=batch_palette,\n",
    "               savefig='../../results/figures_Fig1/baseline_ae_batch_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b666842-4bbd-4d13-9efe-88a184202dce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
