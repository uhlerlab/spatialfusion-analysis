{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2bd366-970e-434b-a928-360004a0309c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "import pathlib as pl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c766b0-713c-46c5-94b5-16a9d040825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f08e1-8858-447d-9603-05e2e31f6ebd",
   "metadata": {},
   "source": [
    "# Import and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c791808-90bc-41cf-903b-5a69378dca85",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc346166-05ef-474d-af0f-92be232bfea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_label_column(gdf: gpd.GeoDataFrame) -> str | None:\n",
    "    \"\"\"Pick a reasonable label column from common QuPath exports.\"\"\"\n",
    "    candidates = [\n",
    "        \"classification_name\",  # from nested 'classification.name'\n",
    "        \"name\",\n",
    "        \"label\",\n",
    "        \"annotation\",\n",
    "        \"class\",\n",
    "        \"type\",\n",
    "    ]\n",
    "    cols = [c for c in gdf.columns if c != gdf.geometry.name]\n",
    "    for c in candidates:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return cols[0] if cols else None\n",
    "\n",
    "\n",
    "def ensure_label_column(gdf: gpd.GeoDataFrame, prefer: str | None) -> str | None:\n",
    "    \"\"\"Ensure there's a flat text label column to use.\"\"\"\n",
    "    if prefer and prefer in gdf.columns:\n",
    "        return prefer\n",
    "\n",
    "    # Some QuPath exports store nested dict in 'classification' with key 'name'\n",
    "    if \"classification\" in gdf.columns and \"classification_name\" not in gdf.columns:\n",
    "        def _extract_name(v):\n",
    "            try:\n",
    "                if isinstance(v, dict):\n",
    "                    return v.get(\"name\")\n",
    "                if isinstance(v, str):\n",
    "                    return json.loads(v).get(\"name\")\n",
    "            except Exception:\n",
    "                pass\n",
    "            return None\n",
    "        gdf[\"classification_name\"] = gdf[\"classification\"].map(_extract_name)\n",
    "\n",
    "    return guess_label_column(gdf)\n",
    "\n",
    "\n",
    "def make_points_gdf(XY: np.ndarray, index, crs) -> gpd.GeoDataFrame:\n",
    "    \"\"\"Create a GeoDataFrame of points from (x, y) coordinates.\"\"\"\n",
    "    points = gpd.GeoSeries((Point(float(x), float(y)) for x, y in XY),\n",
    "                           index=index, name=\"geometry\", crs=crs)\n",
    "    return gpd.GeoDataFrame(geometry=points)\n",
    "\n",
    "\n",
    "def aggregate_labels(join_df: pd.DataFrame, label_col: str, obs_index) -> pd.Series:\n",
    "    \"\"\"Aggregate multiple matches per cell into a semicolon-separated label string.\"\"\"\n",
    "    if label_col not in join_df.columns:\n",
    "        s = join_df.index.to_series().groupby(level=0).size()\n",
    "        out = pd.Series(index=obs_index, dtype=\"object\")\n",
    "        out.loc[s.index] = \"in_annotation\"\n",
    "        return out\n",
    "\n",
    "    agg = (\n",
    "        join_df[label_col]\n",
    "        .groupby(level=0)\n",
    "        .apply(lambda s: \";\".join(sorted(str(v) for v in set(s.dropna()))))\n",
    "    )\n",
    "    out = pd.Series(index=obs_index, dtype=\"object\")\n",
    "    out.loc[agg.index] = agg\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb028f3-88b6-4a80-aca1-df86fe8278e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_palettes_from_adata(adata, palette_specs):\n",
    "    \"\"\"\n",
    "    Build labeled color palettes for categorical columns in adata.obs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata : AnnData\n",
    "        Must have .obs DataFrame containing categorical columns.\n",
    "    palette_specs : dict\n",
    "        Mapping {column_name: palette} where palette can be:\n",
    "          - a string palette name (e.g. \"tab10\")\n",
    "          - a list of RGB colors (custom)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        {column_name: {label: color}} mapping.\n",
    "    \"\"\"\n",
    "    custom_palettes = {}\n",
    "\n",
    "    for col, palette in palette_specs.items():\n",
    "        if col not in adata.obs.columns:\n",
    "            print(f\"âš ï¸ Warning: '{col}' not found in adata.obs â€” skipping.\")\n",
    "            continue\n",
    "\n",
    "        unique_vals = sorted(adata.obs[col].astype(str).dropna().unique())\n",
    "        n_unique = len(unique_vals)\n",
    "\n",
    "        # If user passed a name â†’ generate via seaborn\n",
    "        if isinstance(palette, str):\n",
    "            pal_colors = sns.color_palette(palette, n_colors=n_unique)\n",
    "        # If user passed a list â†’ use directly\n",
    "        elif isinstance(palette, (list, tuple)):\n",
    "            pal_colors = palette[:n_unique]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported palette type for '{col}': {type(palette)}\")\n",
    "\n",
    "        color_dict = dict(zip(unique_vals, pal_colors))\n",
    "        custom_palettes[col] = color_dict\n",
    "\n",
    "    print(f\"âœ… Built palettes for {len(custom_palettes)} columns.\")\n",
    "    return custom_palettes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e3c65-c016-4bf5-b286-b56beec864ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_celltype_spatial_single_split_legend(\n",
    "    df,\n",
    "    color_by=\"celltype\",\n",
    "    sample_id=None,\n",
    "    title=None,\n",
    "    palette_dict=None,         # âœ… added\n",
    "    palette_name=\"tab20\",\n",
    "    s=1.5,\n",
    "    save_svg=True,\n",
    "    output_prefix=\"spatial_plot\",\n",
    "    legend_title=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Nature Geneticsâ€“style spatial scatterplot for one sample,\n",
    "    saving main plot as PNG (raster) and legend separately as SVG (vector).\n",
    "    \"\"\"\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_context(\"talk\")\n",
    "\n",
    "    # --- Subset one sample ---\n",
    "    if sample_id is not None:\n",
    "        df = df[df[\"sample_id\"] == sample_id].copy()\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"Sample ID '{sample_id}' not found in DataFrame.\")\n",
    "\n",
    "    # --- Colors ---\n",
    "    unique_labels = sorted(df[color_by].dropna().unique())\n",
    "    if palette_dict is not None and color_by in palette_dict:\n",
    "        color_dict = palette_dict[color_by]\n",
    "    else:\n",
    "        palette = sns.color_palette(palette_name, n_colors=len(unique_labels))\n",
    "        color_dict = dict(zip(unique_labels, palette))\n",
    "\n",
    "    # --- Main plot ---\n",
    "    fig, ax = plt.subplots(figsize=(6, 5), dpi=300)\n",
    "    sns.scatterplot(\n",
    "        data=df,\n",
    "        x=\"X_coord\", y=\"Y_coord\",\n",
    "        hue=color_by, palette=color_dict,\n",
    "        s=s, alpha=0.9, linewidth=0,\n",
    "        rasterized=True, ax=ax, legend=False\n",
    "    )\n",
    "    ax.invert_yaxis(); ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    for spine in [\"top\", \"right\", \"left\", \"bottom\"]:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.set_xlabel(\"\"); ax.set_ylabel(\"\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # --- Save main figure ---\n",
    "    fname_main = f\"{output_prefix}_{sample_id or 'sample'}_main.png\"\n",
    "    fig.savefig(fname_main, dpi=300, bbox_inches=\"tight\", transparent=True, format=\"png\")\n",
    "    print(f\"Saved main figure: {fname_main}\")\n",
    "\n",
    "    # --- Legend ---\n",
    "    fig_leg, ax_leg = plt.subplots(figsize=(3, 0.5 * len(unique_labels)), dpi=300)\n",
    "    handles = [\n",
    "        plt.Line2D([0], [0], marker='o', color='none', label=label,\n",
    "                   markerfacecolor=color_dict[label], markersize=8)\n",
    "        for label in unique_labels\n",
    "    ]\n",
    "    ax_leg.legend(handles=handles, loc=\"center left\", frameon=False,\n",
    "                  title=legend_title or color_by, title_fontsize=14, fontsize=14)\n",
    "    ax_leg.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_svg:\n",
    "        fname_leg = f\"{output_prefix}_{sample_id or 'sample'}_legend.svg\"\n",
    "        fig_leg.savefig(fname_leg, dpi=300, bbox_inches=\"tight\", transparent=True, format=\"svg\")\n",
    "        print(f\"Saved legend: {fname_leg}\")\n",
    "\n",
    "    plt.close(fig); plt.close(fig_leg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9615065-6aff-4e50-90cf-f017708e5a82",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e0f691-bf34-4d55-8193-dea5a2e83b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- REQUIRED: set your paths ---\n",
    "ADATA_PATH = '../../../Broad_SpatialFoundation/test_data/10X_VisiumHD_LUAD_FFPE/adata.h5ad'\n",
    "GEOJSON_PATH = \"../../../Broad_SpatialFoundation/test_data/10X_VisiumHD_LUAD_FFPE/Visium_HD_Human_Lung_Cancer_HD_Only_Experiment1_tissue_image.btf - 20x_BF_01.geojson\"\n",
    "\n",
    "# --- OPTIONAL: customize these ---\n",
    "OBSM_KEY   = \"spatial\"                         # obsm key with (x, y) in H&E pixel space\n",
    "OUT_PATH   = None                                 # None -> will save next to ADATA_PATH with .annotated.h5ad\n",
    "OUT_COL    = \"region_annotation\"                  # adata.obs column to write labels into\n",
    "LABEL_COL  = 'name'                                 # if you know your label field name in the GeoJSON, set it (e.g., \"name\")\n",
    "                                                   # otherwise the notebook tries to guess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada961f9-b5de-4f0b-8e4f-5b0e1314bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = sc.read_h5ad(ADATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcfc93a-d86c-45f7-a032-4e744afeb683",
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = np.asarray(rawdata.obsm[OBSM_KEY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff7ced-0c56-4f85-8263-e88c7097b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = gpd.read_file(GEOJSON_PATH)\n",
    "if ann.empty:\n",
    "    raise ValueError(\"Annotation GeoJSON has no geometries.\")\n",
    "\n",
    "ann = ann[ann.geometry.notnull()].copy()\n",
    "ann = ann[ann.geometry.geom_type.isin([\"Polygon\", \"MultiPolygon\"])].copy()\n",
    "if ann.empty:\n",
    "    raise ValueError(\"No Polygon/MultiPolygon geometries found in the GeoJSON.\")\n",
    "\n",
    "label_col = ensure_label_column(ann, LABEL_COL)\n",
    "if label_col is None:\n",
    "    label_col = \"_layer\"\n",
    "    ann[label_col] = \"annotation\"\n",
    "\n",
    "print(\"Annotation label column:\", label_col)\n",
    "display(ann.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf8d9e9-5a47-4533-b5ef-a9aa8461aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure CRS aligns; QuPath pixel coords commonly have no CRS, which is fine\n",
    "pts = make_points_gdf(XY, rawdata.obs_names, crs=ann.crs)\n",
    "\n",
    "# Join with predicate='within' (Shapely 2+ / GeoPandas >=0.10)\n",
    "joined = gpd.sjoin(pts, ann[[label_col, ann.geometry.name]], how=\"left\", predicate=\"within\")\n",
    "\n",
    "# Aggregate overlaps and fill missing\n",
    "labels = aggregate_labels(joined, label_col, obs_index=rawdata.obs_names).fillna(\"unlabeled\")\n",
    "rawdata.obs[OUT_COL] = pd.Categorical(labels)\n",
    "\n",
    "print(\"Done assigning labels. Preview value counts:\")\n",
    "display(rawdata.obs[OUT_COL].value_counts(dropna=False).to_frame(\"count\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161b796-4b2d-4b1e-a1d1-6fdca2ac8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.obs[OUT_COL] = rawdata.obs[OUT_COL].replace({'': 'Unassigned', 'Grade 2 Tumor;Grade 3 Tumor': 'Unassigned',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b51cad8-7392-401b-b90c-35c946fba0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.obs = pd.concat([rawdata.obs, pd.DataFrame(rawdata.obsm['spatial'], index=rawdata.obs_names, columns=['X_coord','Y_coord'])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e512e-5db3-4ce3-848d-cfc1bf6ce5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df = rawdata.obs[['region_annotation', 'X_coord','Y_coord']]\n",
    "\n",
    "region_df['sample_id'] = 'VisiumHD_LUAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3879a93a-0ac4-4667-9d68-ac72f50ede07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_filtered = sns.color_palette()\n",
    "tab_filtered = [c for i,c in enumerate(tab_filtered) if i not in [4,6]]\n",
    "\n",
    "tab20_filtered = sns.color_palette('tab20') + sns.color_palette('tab20c')[:11]\n",
    "tab20_filtered = [c for i,c in enumerate(tab20_filtered) if i not in [8,9,12,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d170c-f5f6-4946-aaba-bf6fe4fe76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_specs = {\n",
    "            \"region_annotation\": tab_filtered,\n",
    "        }\n",
    "\n",
    "palette_dict_1 = build_palettes_from_adata(rawdata, palette_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf1534-7060-4167-814b-3ef564359836",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_celltype_spatial_single_split_legend(\n",
    "    region_df,\n",
    "    color_by=\"region_annotation\",\n",
    "    sample_id=None,\n",
    "    title='LUAD\\nPathologist-annotated region',\n",
    "    palette_dict=palette_dict_1,\n",
    "    s=1.5,\n",
    "    save_svg=True,\n",
    "    output_prefix=\"../../../SpatialFusion/results/figures_Fig4/LUAD_pathregion\",\n",
    "    legend_title='Path.-annotated region'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b156ac4a-fecb-4353-9628-bcfdde88c8ae",
   "metadata": {},
   "source": [
    "# Embed scGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af72b65-fbbc-4e6e-8867-ff0084c837f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "import argparse\n",
    "from typing import List, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# --- Logging ---\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"[%(asctime)s] %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    ")\n",
    "log = logging.getLogger(\"hest\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from huggingface_hub import login as hf_login\n",
    "import datasets\n",
    "\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import tifffile\n",
    "import shapely.wkb  # access as shapely.wkb.loads(...)\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81bce7-9fa1-4f9a-ad03-e3fbef374c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_embed_scGPT(\n",
    "    dataset_path: Path,\n",
    "    model_dir: Path,  # dir containing best_model.pt, args.json, vocab.json\n",
    "    output_dir: Path,\n",
    "    n_hvg: int = 1200,\n",
    "    gene_col: str = \"index\",\n",
    "    layer_key: str = \"X\",\n",
    "    log_norm: bool = False,\n",
    "    seed: int = 42,\n",
    "    max_seq_len: int = 1200,\n",
    "    batch_size: int = 16,\n",
    "    input_bins: int = 51,\n",
    "    model_run: str = \"pretrained\",\n",
    "    num_workers: int = 0,\n",
    "):\n",
    "    # Lazy imports from user repo\n",
    "    sys.path.append(str(model_dir.parent))  # allow e.g., /.../Broad_SpatialFoundation/\n",
    "    try:\n",
    "        from sc_foundation_evals import cell_embeddings, scgpt_forward, data, model_output  # noqa: F401\n",
    "        from sc_foundation_evals.helpers.custom_logging import log as sc_log  # noqa: F401\n",
    "    except Exception as e:\n",
    "        raise ImportError(\n",
    "            \"Could not import sc_foundation_evals from your codebase. \"\n",
    "            \"Ensure the repository is available and model_dir parent is in sys.path.\"\n",
    "        ) from e\n",
    "\n",
    "    # Create model\n",
    "    scgpt_model = scgpt_forward.scGPT_instance(\n",
    "        saved_model_path=str(model_dir),\n",
    "        model_run=model_run,\n",
    "        batch_size=batch_size,\n",
    "        save_dir=str(output_dir),\n",
    "        num_workers=num_workers,\n",
    "        explicit_save_dir=True,\n",
    "    )\n",
    "\n",
    "    # Configs and weights\n",
    "    scgpt_model.create_configs(seed=seed, max_seq_len=max_seq_len, n_bins=input_bins)\n",
    "    scgpt_model.load_pretrained_model()\n",
    "\n",
    "    # Data prep\n",
    "    input_data = data.InputData(adata_dataset_path=str(dataset_path))\n",
    "    vocab_list = scgpt_model.vocab.get_stoi().keys()\n",
    "\n",
    "    input_data.preprocess_data(\n",
    "        gene_vocab=vocab_list,\n",
    "        model_type=\"scGPT\",\n",
    "        gene_col=gene_col,\n",
    "        data_is_raw=not log_norm,\n",
    "        counts_layer=layer_key,\n",
    "        n_bins=input_bins,\n",
    "        n_hvg=n_hvg,\n",
    "    )\n",
    "\n",
    "    scgpt_model.tokenize_data(\n",
    "        data=input_data, input_layer_key=\"X_binned\", include_zero_genes=False\n",
    "    )\n",
    "\n",
    "    scgpt_model.extract_embeddings(data=input_data)\n",
    "\n",
    "    out_parquet = output_dir / \"scGPT.parquet\"\n",
    "    pd.DataFrame(\n",
    "        input_data.adata.obsm[\"X_scGPT\"],\n",
    "        index=input_data.adata.obs[\"cell_id\"] if \"cell_id\" in input_data.adata.obs.columns else input_data.adata.obs.index,\n",
    "    ).to_parquet(out_parquet)\n",
    "    print(f\"[scGPT] Wrote embeddings: {out_parquet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d317ba-b786-450e-81e8-016290a25bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(pl.Path(ADATA_PATH).parent / 'embeddings', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed5fac2-92c0-4f8f-a033-2fea04235057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_embed_scGPT(\n",
    "    dataset_path=ADATA_PATH,\n",
    "    model_dir=pl.Path('../../../Broad_SpatialFoundation/scGPT_model/'),\n",
    "    output_dir=pl.Path(ADATA_PATH).parent / 'embeddings',\n",
    "    n_hvg=1200,\n",
    "    gene_col='index',\n",
    "    layer_key='X',\n",
    "    log_norm=False,\n",
    "    seed=42,\n",
    "    max_seq_len=1200,\n",
    "    batch_size=16,\n",
    "    input_bins=51,\n",
    "    model_run=\"pretrained\",\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000534d-7c2a-420f-9e2f-3f3b50769fb6",
   "metadata": {},
   "source": [
    "# Embed UNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7302e1-1862-462a-ba36-5d0013d894f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_UNI_model(model_path: str, device: str = \"cuda\"):\n",
    "    timm_kwargs = {\n",
    "        'model_name': 'vit_giant_patch14_224',\n",
    "        'img_size': 224,\n",
    "        'patch_size': 14,\n",
    "        'depth': 24,\n",
    "        'num_heads': 24,\n",
    "        'init_values': 1e-5,\n",
    "        'embed_dim': 1536,\n",
    "        'mlp_ratio': 2.66667 * 2,\n",
    "        'num_classes': 0,\n",
    "        'no_embed_class': True,\n",
    "        'mlp_layer': timm.layers.SwiGLUPacked,\n",
    "        'act_layer': torch.nn.SiLU,\n",
    "        'reg_tokens': 8,\n",
    "        'dynamic_img_size': True\n",
    "    }\n",
    "\n",
    "    model = timm.create_model(pretrained=False, **timm_kwargs)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=True)\n",
    "    model.eval().to(device)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Lambda(lambda im: im.convert('RGB')),  # ensure 3 channels\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                             std=(0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    return model, transform\n",
    "\n",
    "\n",
    "def process_HDsample_and_embed_UNI(\n",
    "    adata, wsi_path, sample_id, model_path, out_root=\"VisiumHD_processed_data\", device=\"cuda\"\n",
    "):\n",
    "    print('Load UNI model')\n",
    "    model, transform = load_UNI_model(model_path, device)\n",
    "\n",
    "    # ensure output dirs\n",
    "    os.makedirs(f\"{out_root}/{sample_id}/embeddings\", exist_ok=True)\n",
    "\n",
    "    with tifffile.TiffFile(str(wsi_path)) as tif:\n",
    "        wsi = tif.pages[0].asarray()\n",
    "\n",
    "    he_coords = adata.obsm['spatial']\n",
    "\n",
    "    batch_size = 128\n",
    "    embeddings = []\n",
    "    cell_ids = []\n",
    "    batch_imgs, batch_ids = [], []\n",
    "\n",
    "    print(f\"Embedding {len(he_coords)} image patches in batches of {batch_size}...\")\n",
    "    for cid, (x, y) in tqdm(zip(adata.obs_names, he_coords), total=len(adata)):\n",
    "        x, y = int(x), int(y)\n",
    "        x0, x1 = x - 128, x + 128\n",
    "        y0, y1 = y - 128, y + 128\n",
    "\n",
    "        pad_x0 = max(0, -x0)\n",
    "        pad_x1 = max(0, x1 - wsi.shape[1])\n",
    "        pad_y0 = max(0, -y0)\n",
    "        pad_y1 = max(0, y1 - wsi.shape[0])\n",
    "\n",
    "        # slice & pad (handles edges)\n",
    "        patch = np.pad(\n",
    "            wsi[max(0, y0):min(wsi.shape[0], y1), max(0, x0):min(wsi.shape[1], x1)],\n",
    "            ((pad_y0, pad_y1), (pad_x0, pad_x1)) + ((0, 0),) if wsi.ndim == 3 else ((0,0),),\n",
    "            mode=\"constant\"\n",
    "        )\n",
    "\n",
    "        # ensure HxW or HxWxC with C>=1\n",
    "        if patch.ndim == 2:\n",
    "            patch = np.stack([patch]*3, axis=-1)  # grayscale -> RGB\n",
    "\n",
    "        if patch.shape[:2] != (256, 256):\n",
    "            continue\n",
    "\n",
    "        # drop alpha or extra channels if present (e.g., RGBA)\n",
    "        if patch.shape[2] > 3:\n",
    "            patch = patch[:, :, :3]\n",
    "\n",
    "        img = Image.fromarray(patch).convert('RGB')\n",
    "        tensor_img = transform(img)\n",
    "\n",
    "        batch_imgs.append(tensor_img)\n",
    "        batch_ids.append(cid)\n",
    "\n",
    "        if len(batch_imgs) == batch_size:\n",
    "            img_tensor = torch.stack(batch_imgs).to(device)\n",
    "            with torch.inference_mode():\n",
    "                if device.startswith('cuda'):\n",
    "                    with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                        batch_embs = model(img_tensor).to(torch.float16).cpu().numpy()\n",
    "                else:\n",
    "                    batch_embs = model(img_tensor).cpu().numpy()\n",
    "\n",
    "            embeddings.extend(batch_embs)\n",
    "            cell_ids.extend(batch_ids)\n",
    "            batch_imgs.clear()\n",
    "            batch_ids.clear()\n",
    "\n",
    "    # Final batch\n",
    "    if batch_imgs:\n",
    "        img_tensor = torch.stack(batch_imgs).to(device)\n",
    "        with torch.inference_mode():\n",
    "            if device.startswith('cuda'):\n",
    "                with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    batch_embs = model(img_tensor).to(torch.float16).cpu().numpy()\n",
    "            else:\n",
    "                batch_embs = model(img_tensor).cpu().numpy()\n",
    "        embeddings.extend(batch_embs)\n",
    "        cell_ids.extend(batch_ids)\n",
    "\n",
    "    # Save\n",
    "    df = pd.DataFrame(embeddings, index=cell_ids)\n",
    "    out_path = f\"{out_root}/{sample_id}/embeddings/UNI.parquet\"\n",
    "    df.to_parquet(out_path, index=True)\n",
    "    print(f\"Saved {len(df)} embeddings to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff13a742-4050-465a-bb23-c03ac044a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:5\" if torch.cuda.is_available() else \"cpu\"  # target GPU 5 explicitly\n",
    "\n",
    "base_dir = Path('../../../Broad_SpatialFoundation/test_data/')\n",
    "raw_dir  = Path('../../../Broad_SpatialFoundation/test_data/')\n",
    "sample_id = '10X_VisiumHD_LUAD_FFPE'\n",
    "\n",
    "print(f\"\\nðŸ”„ Processing {sample_id}\")\n",
    "output_path = base_dir / sample_id\n",
    "img_dir    = raw_dir / sample_id\n",
    "\n",
    "adata = sc.read_h5ad(output_path / 'adata.h5ad')\n",
    "\n",
    "process_HDsample_and_embed_UNI(\n",
    "    adata,\n",
    "    img_dir / 'Visium_HD_Human_Lung_Cancer_HD_Only_Experiment1_tissue_image.btf',           \n",
    "    sample_id,\n",
    "    \"../../../Broad_SpatialFoundation/UNI/pytorch_model.bin\",\n",
    "    out_root=str(base_dir),\n",
    "    device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b27095-7bef-4c7d-b3f2-70174f20a9b8",
   "metadata": {},
   "source": [
    "# Embed sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2854858-ae4c-4051-8261-8f571ef34db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialfusion.embed.embed import AEInputs, run_full_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255fc5ad-8691-40c5-911a-d9a0c42e0eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = pl.Path('../../../Broad_SpatialFoundation/test_data/')\n",
    "sample_name = '10X_VisiumHD_LUAD_FFPE'\n",
    "output_dir = basepath / sample_name\n",
    "\n",
    "uni_df = pd.read_parquet(pl.Path(output_dir) / 'embeddings' / 'UNI.parquet')\n",
    "scgpt_df = pd.read_parquet(pl.Path(output_dir) / 'embeddings' / 'scGPT.parquet')\n",
    "\n",
    "adata = sc.read_h5ad(basepath / sample_name / 'adata.h5ad')\n",
    "adata.obs = pd.concat([adata.obs, pd.DataFrame(adata.obsm['spatial'], index=adata.obs_names, columns=['X_coord','Y_coord'])],axis=1)\n",
    "adata.obs[\"sample_id\"] = sample_name\n",
    "\n",
    "ae_inputs_by_sample = {\n",
    "    sample_name: AEInputs(adata=adata, z_uni=uni_df, z_scgpt=scgpt_df),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e26a08-d65b-4642-946d-71e482f9aa66",
   "metadata": {},
   "source": [
    "## Embeddings average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8eb44d-1c9b-4876-a453-70c38c7670dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this uses the average version\n",
    "embeddings_df = run_full_embedding(\n",
    "    ae_inputs_by_sample=ae_inputs_by_sample,\n",
    "    ae_model_path='../../../Broad_SpatialFoundation/checkpoint_dir_ae/paired_model_6c22d731.pt',\n",
    "    gcn_model_path='../../../Broad_SpatialFoundation/checkpoint_dir_gcn/gcn_20250828-123835_e926ee8d/model.pt',\n",
    "    device=\"cuda:0\",\n",
    "    combine_mode=\"average\",\n",
    "    spatial_key='spatial',\n",
    "    celltype_key=None,\n",
    "    save_ae_dir=None,  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6feda6-7e96-4a08-a737-7ebdf3ec284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.index = embeddings_df.cell_id\n",
    "\n",
    "out_path = pl.Path(output_dir / \"embeddings\" / \"NicheFinder_new.parquet\")\n",
    "embeddings_df.to_parquet(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e638eba5-61ec-438f-88bc-b037795e74c9",
   "metadata": {},
   "source": [
    "## Embeddings H&E only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1a556c-662a-48ae-960b-030156bd91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this uses the average version\n",
    "embeddings_df = run_full_embedding(\n",
    "    ae_inputs_by_sample=ae_inputs_by_sample,\n",
    "    ae_model_path='../../../Broad_SpatialFoundation/checkpoint_dir_ae/paired_model_6c22d731.pt',\n",
    "    gcn_model_path='../../../Broad_SpatialFoundation/checkpoint_dir_gcn/gcn_20251001-102239_fa6fe395/model.pt',\n",
    "    device=\"cuda:0\",\n",
    "    combine_mode=\"z1\",\n",
    "    spatial_key='spatial',\n",
    "    celltype_key=None,\n",
    "    save_ae_dir=None,  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd2374b-1358-4e8e-be6a-00f5222c2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.index = embeddings_df.cell_id\n",
    "\n",
    "out_path = pl.Path(output_dir / \"embeddings\"/ \"NicheFinder_he_new.parquet\")\n",
    "embeddings_df.to_parquet(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09db09-e0e1-4804-9bd0-0d34576f40ff",
   "metadata": {},
   "source": [
    "# Finetune model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f050ae-a324-4341-ba71-684d8c45b960",
   "metadata": {},
   "source": [
    "First here I need to compute the decoupler estimated pathways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5aa73f-e26a-43c9-8476-82fe1ba356df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pathlib as pl\n",
    "from scipy.sparse import issparse\n",
    "import warnings\n",
    "\n",
    "import scanpy as sc\n",
    "import decoupler as dc\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "sc.set_figure_params(figsize=(3, 3), frameon=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a31de8f-fe57-4b6e-8894-53d564c11e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "progeny = dc.op.progeny(organism=\"human\")\n",
    "progeny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4043f3d-eb9b-420d-b4a2-0e21baee7e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pathway_score(adata, spatial_key=\"spatial_he\", bw=100, cutoff=0.1, net=progeny):\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    \n",
    "    adata.layers[\"norm\"] = adata.X.copy()\n",
    "    dc.pp.knn(adata, key=spatial_key, bw=bw, cutoff=cutoff)\n",
    "    adata.X = adata.obsp[f\"{spatial_key}_connectivities\"].dot(adata.X)\n",
    "\n",
    "    dc.mt.ulm(data=adata, net=net)\n",
    "    score = dc.pp.get_obsm(adata=adata, key=\"score_ulm\")\n",
    "    return adata, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec401049-67b8-420d-a643-c0cdab501ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "actionable_pathways = ['Androgen', 'EGFR', 'Estrogen', 'JAK-STAT', 'MAPK', 'NFkB',\n",
    "       'PI3K', 'TGFb', 'TNFa', 'VEGF',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a677de4c-21eb-4ad9-9429-dfacb0d7de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pathway_score = get_pathway_score(adata, spatial_key=\"spatial\", bw=100, cutoff=0.1)\n",
    "pathway_score = pathway_score.obsm['score_ulm'].loc[:,actionable_pathways]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250d7b8-4107-4ef7-a45b-eaa66436a001",
   "metadata": {},
   "source": [
    "Now I can finetune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a754a6-60cf-49c0-a615-d3ea3f00983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialfusion.finetune.finetune import finetune_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388c41f-bb35-497f-9be9-4aacd00275a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(basepath / sample_name / 'adata.h5ad')\n",
    "adata.obs = pd.concat([adata.obs, pd.DataFrame(adata.obsm['spatial'], index=adata.obs_names, columns=['X_coord','Y_coord'])],axis=1)\n",
    "adata.obs[\"sample_id\"] = sample_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bafdd2-743a-4c9a-9c15-75b847c8a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = {sample_name: adata}\n",
    "\n",
    "preloaded_data = {\n",
    "    sample_name: (uni_df.loc[adata.obs_names], scgpt_df.loc[adata.obs_names])\n",
    "}\n",
    "\n",
    "preloaded_pathway_data = {\n",
    "    sample_name: pathway_score.loc[adata.obs_names]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018a6267-76c7-48d1-a360-a5c8dcbbac60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finetune_models(\n",
    "    samples=[sample_name],\n",
    "    pretrained_ae='../../../Broad_SpatialFoundation/checkpoint_dir_ae/paired_model_6c22d731.pt',\n",
    "    pretrained_gcn='../../../Broad_SpatialFoundation/checkpoint_dir_gcn/gcn_20250828-123835_e926ee8d/model.pt',\n",
    "    save_dir='../../../Broad_SpatialFoundation/finetuned_LUAD_hd',\n",
    "    preloaded_data=preloaded_data,   # instead of base_path\n",
    "    adatas=adatas,                   # instead of loading from disk\n",
    "    preloaded_pathway_data=preloaded_pathway_data,\n",
    "    ae_epochs=5,\n",
    "    gcn_epochs=10,\n",
    "    ae_batch_size=128,\n",
    "    gcn_batch_size=2,\n",
    "    latent_dim=64,\n",
    "    knn_k=30,\n",
    "    subgraph_size=5000,\n",
    "    stride=2500,\n",
    "    use_cls_loss=True,\n",
    "    spatial_key='spatial',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3daae1-c4ea-437f-9b58-acf327d3d492",
   "metadata": {},
   "source": [
    "## Now embed finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155eee2-806b-421c-b186-8371a823278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = pl.Path('../../../Broad_SpatialFoundation/test_data/')\n",
    "sample_name = '10X_VisiumHD_LUAD_FFPE'\n",
    "output_dir = basepath / sample_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3bb08-0c7a-4581-9ee6-fd1c5bb76222",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_df = pd.read_parquet(pl.Path(output_dir) / 'embeddings' / 'UNI.parquet')\n",
    "scgpt_df = pd.read_parquet(pl.Path(output_dir) / 'embeddings' / 'scGPT.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af8ab8-61c8-4b8e-a135-cf305afe49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(basepath / sample_name / 'adata.h5ad')\n",
    "adata.obs = pd.concat([adata.obs, pd.DataFrame(adata.obsm['spatial'], index=adata.obs_names, columns=['X_coord','Y_coord'])],axis=1)\n",
    "adata.obs[\"sample_id\"] = sample_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff8d57e-c991-4528-af21-60e3efec2a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_inputs_by_sample = {\n",
    "    sample_name: AEInputs(adata=adata, z_uni=uni_df, z_scgpt=scgpt_df),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13927fe2-5352-4733-8635-c2690c475f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this uses the average version\n",
    "embeddings_df = run_full_embedding(\n",
    "    ae_inputs_by_sample=ae_inputs_by_sample,\n",
    "    ae_model_path='../../../Broad_SpatialFoundation/finetuned_LUAD_hd/paired_model_finetuned.pt',\n",
    "    gcn_model_path='../../../Broad_SpatialFoundation/finetuned_LUAD_hd/gcn_finetuned/model.pt',\n",
    "    device=\"cuda:0\",\n",
    "    combine_mode=\"average\",\n",
    "    spatial_key='spatial',\n",
    "    celltype_key=None,\n",
    "    save_ae_dir=None,  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fcce27-710d-4bca-a378-776176ba90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df.index = embeddings_df.cell_id\n",
    "\n",
    "out_path = pl.Path(output_dir / \"embeddings\"/ \"NicheFinder_finetuned_new.parquet\")\n",
    "embeddings_df.to_parquet(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f880daf-5857-49eb-963e-b12f5d77c17c",
   "metadata": {},
   "source": [
    "# SDMBench"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7ff9bd-3d15-4009-9021-a8cc7e9d8310",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698430b3-7879-421e-86ac-298d0776a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb20b9-12c5-48f4-8906-1d3747f82798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_PAS_fast(clusterlabel, location, k=10):\n",
    "    clusterlabel = np.array(clusterlabel)\n",
    "    location = np.array(location)\n",
    "\n",
    "    # Fit NearestNeighbors (ignore self-match later)\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='auto').fit(location)\n",
    "    distances, indices = nbrs.kneighbors(location)\n",
    "\n",
    "    # Remove self (first column is self in most cases)\n",
    "    neighbor_indices = indices[:, 1:]  # shape: (n_samples, k)\n",
    "\n",
    "    # Check PAS condition\n",
    "    mismatches = np.array([\n",
    "        np.sum(clusterlabel[neighbor_indices[i]] != clusterlabel[i]) > (k / 2)\n",
    "        for i in range(len(clusterlabel))\n",
    "    ])\n",
    "\n",
    "    return np.sum(mismatches) / len(clusterlabel)\n",
    "\n",
    "\n",
    "def compute_CHAOS_fast(clusterlabel, location):\n",
    "    clusterlabel = np.array(clusterlabel)\n",
    "    location = np.array(location)\n",
    "    matched_location = StandardScaler().fit_transform(location)\n",
    "\n",
    "    clusterlabel_unique = np.unique(clusterlabel)\n",
    "    dist_val = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for k in tqdm(clusterlabel_unique, desc=\"Computing CHAOS\"):\n",
    "        cluster_mask = clusterlabel == k\n",
    "        location_cluster = matched_location[cluster_mask]\n",
    "        n = location_cluster.shape[0]\n",
    "\n",
    "        if n <= 2:\n",
    "            continue\n",
    "\n",
    "        # Use NearestNeighbors to find 1-NN distances\n",
    "        nbrs = NearestNeighbors(n_neighbors=2, algorithm='auto').fit(location_cluster)\n",
    "        distances, _ = nbrs.kneighbors(location_cluster)\n",
    "\n",
    "        # distances[:, 0] is zero (self), distances[:, 1] is nearest neighbor\n",
    "        dist_val += np.sum(distances[:, 1])\n",
    "        total_count += n\n",
    "\n",
    "    return dist_val / total_count if total_count > 0 else np.nan\n",
    "\n",
    "\n",
    "def compute_ASW_fast(adata, pred_key, spatial_key='spatial'):\n",
    "    coords = adata.obsm[spatial_key]\n",
    "    labels = adata.obs[pred_key]\n",
    "    return silhouette_score(X=coords, labels=labels, metric='euclidean')\n",
    "\n",
    "def compute_ARI(adata,gt_key,pred_key):\n",
    "        return adjusted_rand_score(adata.obs[gt_key],adata.obs[pred_key])\n",
    "\n",
    "def compute_NMI(adata,gt_key,pred_key):\n",
    "    return normalized_mutual_info_score(adata.obs[gt_key],adata.obs[pred_key])\n",
    "\n",
    "def compute_HOM(adata,gt_key,pred_key):\n",
    "    return homogeneity_score(adata.obs[gt_key],adata.obs[pred_key])\n",
    "\n",
    "def compute_COM(adata,gt_key,pred_key):\n",
    "    return completeness_score(adata.obs[gt_key],adata.obs[pred_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b403ee19-fbd1-4f40-ab40-2fac1016a920",
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = pl.Path('../../../Broad_SpatialFoundation/test_data/')\n",
    "sample_name = '10X_VisiumHD_LUAD_FFPE'\n",
    "output_dir = basepath / sample_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c822b0-0bf8-4dce-b6c3-9f3c2ca9fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = rawdata.copy()\n",
    "\n",
    "emb_df = pd.read_parquet(basepath / sample_name / 'embeddings' / 'NicheFinder_new.parquet')\n",
    "\n",
    "emb_he_df = pd.read_parquet(basepath / sample_name / 'embeddings' / 'NicheFinder_he_new.parquet')\n",
    "\n",
    "emb_finetuned_df = pd.read_parquet(basepath / sample_name / 'embeddings' / 'NicheFinder_finetuned_new.parquet')\n",
    "\n",
    "nichecompass_df = pd.read_parquet(basepath / sample_name / 'embeddings' / 'nichecompass.parquet')\n",
    "\n",
    "banksy_df = pd.read_parquet(basepath / sample_name / 'embeddings' / 'banksy.parquet')\n",
    "\n",
    "banksy_08_df = pd.read_parquet(basepath / sample_name / 'embeddings' / 'banksy_08.parquet')\n",
    "\n",
    "scgptspatial_df = pd.read_parquet(basepath / sample_name / 'embeddings' / 'scGPTspatial.parquet')\n",
    "\n",
    "omiclip_text_df = pd.read_parquet(basepath / sample_name / 'embeddings' / 'OmiCLIP_text_emb.parquet')\n",
    "\n",
    "omiclip_image_df = pd.read_parquet(basepath / sample_name / 'embeddings' / 'OmiCLIP_image_emb.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04760c02-f8ed-423d-be7e-2162ba8b3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = adata[adata.obs_names.intersection(emb_df.index)].copy()\n",
    "\n",
    "adata.obsm['gcn'] = emb_df.loc[adata.obs_names,['0','1','2','3','4','5','6','7','8','9']]\n",
    "\n",
    "adata.obsm['gcn_he'] = emb_he_df.loc[adata.obs_names,['0','1','2','3','4','5','6','7','8','9']]\n",
    "\n",
    "adata.obsm['gcn_finetuned'] = emb_finetuned_df.loc[adata.obs_names,['0','1','2','3','4','5','6','7','8','9']]\n",
    "\n",
    "adata.obsm['nichecompass'] = nichecompass_df.loc[adata.obs_names]\n",
    "\n",
    "adata.obsm['banksy'] = banksy_df.loc[adata.obs_names]\n",
    "\n",
    "adata.obsm['banksy_08'] = banksy_08_df.loc[adata.obs_names]\n",
    "\n",
    "adata.obsm['scgptspatial'] = scgptspatial_df.loc[adata.obs_names]\n",
    "\n",
    "adata.obsm['scgptspatial'] = scgptspatial_df.loc[adata.obs_names]\n",
    "\n",
    "adata.obsm['omiclip_text'] = omiclip_text_df.loc[adata.obs_names]\n",
    "\n",
    "adata.obsm['omiclip_image'] = omiclip_image_df.loc[adata.obs_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab5845e-b27c-4dbd-996f-673ca5846edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_obs = pd.read_csv('benchmark_luad_hd_obs.csv', index_col=0)\n",
    "\n",
    "adata_obs.index = adata_obs.index.astype(str)\n",
    "\n",
    "adata.obs = adata_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab568452-5daf-4cb2-9a4b-e0ecb4a0b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep = 'gcn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7786df7d-f59b-4e8b-aa2d-32afb4760d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata, resolution=0.12, flavor=\"igraph\", n_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64574e-c9fa-4677-adf8-a5f5c877f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster sizes\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Make mapping: old â†’ new (ranked by size)\n",
    "mapping = {old: str(new) for new, old in enumerate(counts.index)}\n",
    "\n",
    "# Apply mapping\n",
    "adata.obs['leiden'] = adata.obs['leiden'].map(mapping).astype('category')\n",
    "\n",
    "# (optional) sort categories by their new numeric label\n",
    "adata.obs['leiden'].cat.reorder_categories(sorted(adata.obs['leiden'].cat.categories, key=int))\n",
    "\n",
    "print(\"Cluster relabeling done âœ…\")\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "display(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a56b72-942d-480a-9689-2b21e6cf8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['leiden_gcn'] =  adata.obs.leiden.replace({'11': '10', '12': '10', '13': '10', '14': '10',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eefc704-728d-4601-9617-fac381d7cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep = 'gcn_he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14546240-b37e-47d5-8c4d-74bf539698e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata, resolution=0.1, flavor=\"igraph\", n_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e31a08-7887-4475-a8a7-af5843a65bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster sizes\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Make mapping: old â†’ new (ranked by size)\n",
    "mapping = {old: str(new) for new, old in enumerate(counts.index)}\n",
    "\n",
    "# Apply mapping\n",
    "adata.obs['leiden'] = adata.obs['leiden'].map(mapping).astype('category')\n",
    "\n",
    "# (optional) sort categories by their new numeric label\n",
    "adata.obs['leiden'].cat.reorder_categories(sorted(adata.obs['leiden'].cat.categories, key=int))\n",
    "\n",
    "print(\"Cluster relabeling done âœ…\")\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "display(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eccae7-1965-4583-b99f-f96fbf0c2f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['leiden_gcn_he'] =  adata.obs.leiden.replace({'11': '10', '12': '10', '13': '10',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ae1a2-6911-49dd-b4c8-471c7c4cdcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep = 'gcn_finetuned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd8ba0-734b-46b6-84b2-9f9be54574a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata, resolution=0.14, flavor=\"igraph\", n_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b54b4-92be-48e5-baf8-d98daae170de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster sizes\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Make mapping: old â†’ new (ranked by size)\n",
    "mapping = {old: str(new) for new, old in enumerate(counts.index)}\n",
    "\n",
    "# Apply mapping\n",
    "adata.obs['leiden'] = adata.obs['leiden'].map(mapping).astype('category')\n",
    "\n",
    "# (optional) sort categories by their new numeric label\n",
    "adata.obs['leiden'].cat.reorder_categories(sorted(adata.obs['leiden'].cat.categories, key=int))\n",
    "\n",
    "print(\"Cluster relabeling done âœ…\")\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "display(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea74e82-57ce-4482-baff-d38ffe65f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['leiden_gcn_finetuned'] =  adata.obs.leiden.replace({'11': '10', '12': '10',}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d0b8d-3cd0-4cd1-a811-d82f392c3ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep = 'nichecompass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b140055-43f9-4cf8-b473-1fd5b48da140",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata, resolution=0.4, flavor=\"igraph\", n_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece88c0-3af6-4f90-9558-a9f51396057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster sizes\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Make mapping: old â†’ new (ranked by size)\n",
    "mapping = {old: str(new) for new, old in enumerate(counts.index)}\n",
    "\n",
    "# Apply mapping\n",
    "adata.obs['leiden'] = adata.obs['leiden'].map(mapping).astype('category')\n",
    "\n",
    "# (optional) sort categories by their new numeric label\n",
    "adata.obs['leiden'].cat.reorder_categories(sorted(adata.obs['leiden'].cat.categories, key=int))\n",
    "\n",
    "print(\"Cluster relabeling done âœ…\")\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "display(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15a4aa-6813-4673-9d07-08069303ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['leiden_nichecompass'] =  adata.obs.leiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd40d6-3fc3-473b-81f1-03ce12c0e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep = 'banksy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c044b6cc-ba91-46cd-85b0-e1f1a745116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata, resolution=0.2, flavor=\"igraph\", n_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea0852-4132-44dd-9fb2-ee50eeec66a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster sizes\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Make mapping: old â†’ new (ranked by size)\n",
    "mapping = {old: str(new) for new, old in enumerate(counts.index)}\n",
    "\n",
    "# Apply mapping\n",
    "adata.obs['leiden'] = adata.obs['leiden'].map(mapping).astype('category')\n",
    "\n",
    "# (optional) sort categories by their new numeric label\n",
    "adata.obs['leiden'].cat.reorder_categories(sorted(adata.obs['leiden'].cat.categories, key=int))\n",
    "\n",
    "print(\"Cluster relabeling done âœ…\")\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "display(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ca01a-c367-4942-9d61-fdba7ff35610",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['leiden_banksy'] =  adata.obs.leiden.replace({'11': '10',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19319e-b522-4486-a26e-34a1bb8d6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep = 'banksy_08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff8eab-3130-4198-a6eb-60a6974cab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata, resolution=0.22, flavor=\"igraph\", n_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42faebf3-ab61-477b-8b48-8a0c922d9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster sizes\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Make mapping: old â†’ new (ranked by size)\n",
    "mapping = {old: str(new) for new, old in enumerate(counts.index)}\n",
    "\n",
    "# Apply mapping\n",
    "adata.obs['leiden'] = adata.obs['leiden'].map(mapping).astype('category')\n",
    "\n",
    "# (optional) sort categories by their new numeric label\n",
    "adata.obs['leiden'].cat.reorder_categories(sorted(adata.obs['leiden'].cat.categories, key=int))\n",
    "\n",
    "print(\"Cluster relabeling done âœ…\")\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "display(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d9712-b5d1-43bf-baf6-8b8c3baaafee",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['leiden_banksy_08'] =  adata.obs.leiden.replace({'11': '10', '12': '10','13': '10', '14': '10','15': '10',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0ae4d-1a4c-4484-8ba0-7362fdb2eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep = 'scgptspatial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2502a980-5a9f-4283-9bc9-4317d2eb9cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata, resolution=0.7, flavor=\"igraph\", n_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c82c52b-84bf-4f39-846b-e7e530eb731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster sizes\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Make mapping: old â†’ new (ranked by size)\n",
    "mapping = {old: str(new) for new, old in enumerate(counts.index)}\n",
    "\n",
    "# Apply mapping\n",
    "adata.obs['leiden'] = adata.obs['leiden'].map(mapping).astype('category')\n",
    "\n",
    "# (optional) sort categories by their new numeric label\n",
    "adata.obs['leiden'].cat.reorder_categories(sorted(adata.obs['leiden'].cat.categories, key=int))\n",
    "\n",
    "print(\"Cluster relabeling done âœ…\")\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "display(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831327b8-ddc5-47cb-9d6a-0902de5eeede",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['leiden_scgptspatial'] =  adata.obs.leiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b04295-d31c-4586-913b-4a78423a7281",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep = 'omiclip_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187eec00-61e4-4787-b221-eaa363a38186",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata, resolution=0.65, flavor=\"igraph\", n_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821149d-eb3a-4704-888e-b292e124b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster sizes\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Make mapping: old â†’ new (ranked by size)\n",
    "mapping = {old: str(new) for new, old in enumerate(counts.index)}\n",
    "\n",
    "# Apply mapping\n",
    "adata.obs['leiden'] = adata.obs['leiden'].map(mapping).astype('category')\n",
    "\n",
    "# (optional) sort categories by their new numeric label\n",
    "adata.obs['leiden'].cat.reorder_categories(sorted(adata.obs['leiden'].cat.categories, key=int))\n",
    "\n",
    "print(\"Cluster relabeling done âœ…\")\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "display(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e8ec32-7214-4638-b021-d18911c25360",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['leiden_omiclip_text'] =  adata.obs.leiden.replace({'11': '10'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a421e-1b8f-4500-8bd5-7ccb10ccdf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.neighbors(adata, use_rep = 'omiclip_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee870ac-38a1-45ee-9ebc-ac45ac2bbb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata, resolution=0.1, flavor=\"igraph\", n_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e525a46-f19f-4c16-9a01-41929306f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster sizes\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Make mapping: old â†’ new (ranked by size)\n",
    "mapping = {old: str(new) for new, old in enumerate(counts.index)}\n",
    "\n",
    "# Apply mapping\n",
    "adata.obs['leiden'] = adata.obs['leiden'].map(mapping).astype('category')\n",
    "\n",
    "# (optional) sort categories by their new numeric label\n",
    "adata.obs['leiden'].cat.reorder_categories(sorted(adata.obs['leiden'].cat.categories, key=int))\n",
    "\n",
    "print(\"Cluster relabeling done âœ…\")\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "display(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe25bd-a616-4431-92b1-9f2e901a8771",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['leiden_omiclip_image'] =  adata.obs.leiden.replace({'11': '10'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b237013f-59d0-4985-b3cb-074691b77b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "sc.tl.pca(adata)\n",
    "\n",
    "sc.pp.neighbors(adata, use_rep='X_pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f812fd2e-006b-4068-a7d4-ecbe112cbf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.leiden(adata, resolution=0.8, flavor=\"igraph\", n_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb92e76-870e-4b73-8ae9-bea7be8af7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster sizes\n",
    "counts = adata.obs['leiden'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Make mapping: old â†’ new (ranked by size)\n",
    "mapping = {old: str(new) for new, old in enumerate(counts.index)}\n",
    "\n",
    "# Apply mapping\n",
    "adata.obs['leiden'] = adata.obs['leiden'].map(mapping).astype('category')\n",
    "\n",
    "# (optional) sort categories by their new numeric label\n",
    "adata.obs['leiden'].cat.reorder_categories(sorted(adata.obs['leiden'].cat.categories, key=int))\n",
    "\n",
    "print(\"Cluster relabeling done âœ…\")\n",
    "display(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1e67f-6f1f-4c00-9ac5-70461ea284a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['leiden_scanpy'] = adata.obs.leiden.replace({'11': '10',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef7867-2bec-4c58-b0a2-dc4914cf4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.to_csv('benchmark_luad_hd_obs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7691e79-0120-426d-85de-cd2126a1209a",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e5806-3be8-483d-a9e3-eec8353d1601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_metrics(adata, clustering_keys, ground_truth_key='path_region', spatial_key='spatial_px'):\n",
    "    results = {}\n",
    "\n",
    "    for method_name, cluster_key in clustering_keys.items():\n",
    "        metrics = {\n",
    "            'ARI': compute_ARI(adata, cluster_key, ground_truth_key),\n",
    "            'NMI': compute_NMI(adata, cluster_key, ground_truth_key),\n",
    "            'HOM': compute_HOM(adata, cluster_key, ground_truth_key),\n",
    "            'COM': compute_COM(adata, cluster_key, ground_truth_key),\n",
    "            'PAS': compute_PAS_fast(adata.obs[cluster_key], adata.obsm[spatial_key]),\n",
    "            'CHAOS': compute_CHAOS_fast(adata.obs[cluster_key], adata.obsm[spatial_key]),\n",
    "        }\n",
    "        results[method_name] = metrics\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def format_number(value):\n",
    "    \"\"\"Format numbers: scientific notation if <0.01, else 2 decimals.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    if abs(value) < 0.01 and value != 0:\n",
    "        return f\"{value:.0e}\"  # 1 decimal in scientific notation, e.g. 3.4e-04\n",
    "    else:\n",
    "        return f\"{value:.2f}\"  # two decimals otherwise\n",
    "\n",
    "def plot_benchmark_heatmap(\n",
    "    results_df,\n",
    "    title=\"Spatial clustering benchmark\",\n",
    "    savefig=None,\n",
    "    metric_order=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Nature Geneticsâ€“style benchmarking heatmap showing method rankings across metrics.\n",
    "    Allows manual control of metric order.\n",
    "    \"\"\"\n",
    "\n",
    "    lower_better = {'PAS', 'CHAOS'}\n",
    "\n",
    "    # --- Default metric order ---\n",
    "    if metric_order is None:\n",
    "        metric_order = list(results_df.index)\n",
    "\n",
    "    # --- Normalize scores ---\n",
    "    df_norm = results_df.copy()\n",
    "    for metric in df_norm.index:\n",
    "        vals = df_norm.loc[metric]\n",
    "        if metric in lower_better:\n",
    "            vals = -vals\n",
    "        df_norm.loc[metric] = (vals - vals.min()) / (vals.max() - vals.min() + 1e-9)\n",
    "\n",
    "    # --- Rank per metric ---\n",
    "    ranks = results_df.copy()\n",
    "    for metric in ranks.index:\n",
    "        ranks.loc[metric] = results_df.loc[metric].rank(ascending=(metric in lower_better))\n",
    "\n",
    "    # --- Prepare longform for plotting ---\n",
    "    df_plot = df_norm.reset_index().melt(\n",
    "        id_vars='index', var_name='Method', value_name='Normalized'\n",
    "    ).rename(columns={'index': 'Metric'})\n",
    "\n",
    "    df_plot['Raw'] = results_df.reset_index().melt(\n",
    "        id_vars='index', var_name='Method', value_name='Raw'\n",
    "    )['Raw']\n",
    "\n",
    "    df_plot['Rank'] = ranks.reset_index().melt(\n",
    "        id_vars='index', var_name='Method', value_name='Rank'\n",
    "    )['Rank']\n",
    "\n",
    "    # Add directional arrows\n",
    "    df_plot['MetricLabel'] = df_plot['Metric'].apply(\n",
    "        lambda m: f\"{m} {'â†“' if m in lower_better else 'â†‘'}\"\n",
    "    )\n",
    "\n",
    "    # --- Construct ordered MetricLabel list ---\n",
    "    metric_order_labels = []\n",
    "    for m in metric_order:\n",
    "        arrow = 'â†“' if m in lower_better else 'â†‘'\n",
    "        metric_order_labels.append(f\"{m} {arrow}\")\n",
    "\n",
    "    # --- Heatmap data matrix ---\n",
    "    method_order = results_df.columns.tolist()\n",
    "    df_matrix = df_plot.pivot_table(\n",
    "        index=\"MetricLabel\", columns=\"Method\", values=\"Normalized\"\n",
    "    ).loc[metric_order_labels, method_order]\n",
    "\n",
    "    # --- Aesthetics ---\n",
    "    sns.set_theme(style=\"white\", context=\"talk\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(1.3 * len(method_order), 0.8 * len(metric_order)), dpi=300)\n",
    "    # Enhance contrast near the top (gamma correction)\n",
    "    gamma = 3  ### THIS IS ONLY FOR THE COLOR FOR PLOTTING PURPOSES, NOT THE NUMBERS!\n",
    "    df_matrix_contrast = df_matrix ** gamma\n",
    "    sns.heatmap(\n",
    "        df_matrix_contrast,\n",
    "        #cmap=\"vlag\",\n",
    "        cmap = LinearSegmentedColormap.from_list(\n",
    "            \"vlag_red\",\n",
    "            [\"#fee8ef\",  # very light pink\n",
    "             \"#f4a3a8\",  # pastel red\n",
    "             \"#d95858\",  # mid red\n",
    "             \"#b40426\"]  # vlag red (vivid crimson)\n",
    "        ),\n",
    "        cbar=False,\n",
    "        ax=ax,\n",
    "        linewidths=0,\n",
    "        square=True,\n",
    "    )\n",
    "\n",
    "    # --- Adaptive text color (white on dark, black on light) ---\n",
    "    #cmap = plt.get_cmap(\"vlag\")\n",
    "    cmap = LinearSegmentedColormap.from_list(\n",
    "        \"vlag_red\",\n",
    "        [\"#fee8ef\",  # very light pink\n",
    "         \"#f4a3a8\",  # pastel red\n",
    "         \"#d95858\",  # mid red\n",
    "         \"#b40426\"]  # vlag red (vivid crimson)\n",
    "    )\n",
    "\n",
    "    for i, metric in enumerate(df_matrix.index):\n",
    "        base_metric = metric.split()[0]\n",
    "        for j, method in enumerate(df_matrix.columns):\n",
    "            raw_val = results_df.loc[base_metric, method]\n",
    "            norm_val = df_matrix.loc[metric, method]\n",
    "\n",
    "            # Compute luminance for adaptive color\n",
    "            rgb = np.array(cmap(norm_val)[:3])\n",
    "            luminance = 0.2126 * rgb[0] + 0.7152 * rgb[1] + 0.0722 * rgb[2]\n",
    "            text_color = \"black\" if luminance > 0.5 else \"white\"\n",
    "\n",
    "            ax.text(\n",
    "                j + 0.5, i + 0.5,\n",
    "                format_number(raw_val),\n",
    "                ha='center', va='center',\n",
    "                color=text_color,\n",
    "                fontsize=8,\n",
    "                fontweight='normal',\n",
    "            )\n",
    "\n",
    "    # --- Formatting ---\n",
    "    ax.set_title(title, fontsize=10, pad=14, fontweight='normal')\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\", fontsize=10, fontweight='normal')\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=10, fontweight='normal')\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if savefig:\n",
    "        fig.savefig(\n",
    "            savefig,\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=300,\n",
    "            format=savefig.split('.')[-1],\n",
    "            transparent=True\n",
    "        )\n",
    "        print(f\"Saved: {savefig}\")\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe18d46-327e-486d-a698-3b48f5486d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_obs = pd.read_csv('benchmark_luad_hd_obs.csv', index_col=0)\n",
    "\n",
    "adata_obs.index = adata_obs.index.astype(str)\n",
    "\n",
    "adata.obs = adata_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c15572-ded5-42a6-84e5-a53cae6a49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_keys = {\n",
    "    'SpatialFusion': 'leiden_gcn',\n",
    "    'SpatialFusion (H&E)': 'leiden_gcn_he',\n",
    "    'SpatialFusion (finetuned)': 'leiden_gcn_finetuned',\n",
    "    'NicheCompass': 'leiden_nichecompass',\n",
    "    'BANKSY': 'leiden_banksy_08',\n",
    "    'scGPT-spatial': 'leiden_scgptspatial',\n",
    "    'OmiCLIP text': 'leiden_omiclip_text',\n",
    "    'OmiCLIP image': 'leiden_omiclip_image',\n",
    "    'Scanpy': 'leiden_scanpy',\n",
    "}\n",
    "\n",
    "results_df = compute_all_metrics(adata, clustering_keys, ground_truth_key='region_annotation', spatial_key='spatial')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9518aac-6cf9-4c08-a08f-005210d66789",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benchmark_heatmap(results_df, title=\"LUAD Benchmark\", savefig='../../../SpatialFusion/results/figures_Fig4/LUAD_HD_benchmark.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed21b7-9440-40be-9feb-13845371401c",
   "metadata": {},
   "source": [
    "## Plot the clusters in space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d436537-3854-4be3-aa0e-d2d79bb2904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spatial_clusters_panel(\n",
    "    adata,\n",
    "    method_mapping,\n",
    "    color_dict,\n",
    "    coord_keys=(\"X_coord\", \"Y_coord\"),\n",
    "    ncols=5,\n",
    "    savefig=None,\n",
    "    rasterize_points=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot spatial clustering panels for multiple methods in a Nature Genetics style.\n",
    "    \"\"\"\n",
    "\n",
    "    x_key, y_key = coord_keys\n",
    "    method_keys = list(method_mapping.values())\n",
    "    method_titles = list(method_mapping.keys())\n",
    "    n_methods = len(method_keys)\n",
    "    nrows = math.ceil(n_methods / ncols)\n",
    "\n",
    "    # --- Shared color palette across all cluster IDs (as strings) ---\n",
    "    all_labels = np.unique(\n",
    "        np.concatenate([\n",
    "            adata.obs[k].astype(str).values for k in method_keys\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # --- Figure style ---\n",
    "    sns.set_style(\"white\")\n",
    "    sns.set_context(\"talk\", font_scale=1.3)\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows, ncols=ncols, figsize=(5.5 * ncols, 5 * nrows), dpi=300\n",
    "    )\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for i, (display_name, method) in enumerate(method_mapping.items()):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # --- Convert hue column to string to match color_dict keys ---\n",
    "        hue_values = adata.obs[method].astype(str)\n",
    "\n",
    "        sns.scatterplot(\n",
    "            x=adata.obs[x_key],\n",
    "            y=adata.obs[y_key],\n",
    "            hue=hue_values,\n",
    "            palette=color_dict[method],\n",
    "            s=1,\n",
    "            linewidth=0,\n",
    "            alpha=0.9,\n",
    "            ax=ax,\n",
    "            legend=False,\n",
    "            rasterized=rasterize_points,\n",
    "        )\n",
    "\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "        # --- Titles & styling ---\n",
    "        ax.set_title(display_name, fontsize=14, fontweight=\"normal\", pad=10)\n",
    "        ax.set_xlabel(\"\", fontsize=18, labelpad=8, fontweight=\"normal\")\n",
    "        ax.set_ylabel(\"\", fontsize=18, labelpad=8, fontweight=\"normal\")\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        for spine in [\"top\", \"right\", \"left\", \"bottom\"]:\n",
    "            ax.spines[spine].set_visible(False)\n",
    "        ax.grid(False)\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # --- Shared legend ---\n",
    "    rep_method = list(color_dict.keys())[0]\n",
    "    rep_palette = color_dict[rep_method]\n",
    "    \n",
    "    handles = []\n",
    "    for label in sorted(all_labels):\n",
    "        if label in rep_palette:\n",
    "            handles.append(\n",
    "                plt.Line2D(\n",
    "                    [0], [0],\n",
    "                    marker=\"o\",\n",
    "                    color=\"none\",\n",
    "                    markerfacecolor=rep_palette[label],\n",
    "                    markersize=8,\n",
    "                    label=label,\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    legend_fig = plt.figure(figsize=(2.5, 0.4 * len(handles)), dpi=300)\n",
    "    legend_fig.legend(\n",
    "        handles=handles,\n",
    "        loc=\"center\",\n",
    "        title=\"Cluster\",\n",
    "        frameon=False,\n",
    "        ncol=1,\n",
    "        fontsize=12,\n",
    "        title_fontsize=14,\n",
    "    )\n",
    "    legend_fig.tight_layout()\n",
    "    \n",
    "    if savefig:\n",
    "        fig.savefig(\n",
    "            f\"{savefig}_panel.png\",\n",
    "            dpi=200,\n",
    "            bbox_inches=\"tight\",\n",
    "            transparent=True,\n",
    "        )\n",
    "        legend_fig.savefig(\n",
    "            f\"{savefig}_legend.svg\",\n",
    "            dpi=300,\n",
    "            bbox_inches=\"tight\",\n",
    "            transparent=True,\n",
    "        )\n",
    "        print(f\"Saved: {savefig}_panel.png and {savefig}_legend.svg\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close(legend_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bc21d0-9421-4186-add2-1578c1b233eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "leiden_cols = [\n",
    "       'leiden_gcn', 'leiden_gcn_he',\n",
    "       'leiden_gcn_finetuned', 'leiden_nichecompass', \n",
    "       'leiden_scgptspatial',\n",
    "       'leiden_scanpy', 'leiden_omiclip_text',\n",
    "       'leiden_omiclip_image', 'leiden_banksy_08']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2bca4-4561-48eb-a890-223e9fb3b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette_specs = {\n",
    "            l: tab20_filtered for l in leiden_cols\n",
    "        }\n",
    "\n",
    "palette_dict_2 = build_palettes_from_adata(adata, palette_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be870f4-a72b-41ff-91e4-efdf729ececa",
   "metadata": {},
   "outputs": [],
   "source": [
    "method_keys = list(clustering_keys.values())\n",
    "\n",
    "plot_spatial_clusters_panel(\n",
    "    adata,\n",
    "    color_dict=palette_dict_2,\n",
    "    method_mapping=clustering_keys,\n",
    "    ncols=5,\n",
    "    savefig='../../../SpatialFusion/results/figures_Fig4/LUAD_HD_panel_viz_clusters.svg',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0079d67-e006-4349-9ebd-6476e6ad55bf",
   "metadata": {},
   "source": [
    "# Co-occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a950747-8ae6-4d7a-ba0b-83af6267b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute the cross-tabulation (co-occurrence counts)\n",
    "heatmap_data = pd.crosstab(adata.obs['region_annotation'], adata.obs['leiden_gcn'])\n",
    "heatmap_data = heatmap_data.div(heatmap_data.sum(axis=1), axis=0)*100\n",
    "heatmap_data = heatmap_data.astype(int)\n",
    "\n",
    "# Step 2: Plot the heatmap\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\"d\", cmap=\"Blues\",ax=ax)\n",
    "ax.set_xlabel('SpatialFusion niches')\n",
    "ax.set_ylabel('Region annotations')\n",
    "ax.set_title('SpatialFusion co-occurrence')\n",
    "fig.savefig('../../../SpatialFusion/results/figures_Fig4/LUAD_SpatialFusion_confusion.svg', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de53a17-51bf-4c65-b027-0177d4d0d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute the cross-tabulation (co-occurrence counts)\n",
    "heatmap_data = pd.crosstab(adata.obs['region_annotation'], adata.obs['leiden_nichecompass'])\n",
    "heatmap_data = heatmap_data.div(heatmap_data.sum(axis=1), axis=0)*100\n",
    "heatmap_data = heatmap_data.astype(int)\n",
    "\n",
    "# Step 2: Plot the heatmap\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\"d\", cmap=\"Blues\",ax=ax)\n",
    "ax.set_xlabel('NicheCompass niches')\n",
    "ax.set_ylabel('Region annotations')\n",
    "ax.set_title('NicheCompass co-occurrence')\n",
    "fig.savefig('../../../SpatialFusion/results/figures_Fig4/LUAD_NicheCompass_confusion.svg', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e763afaa-2dea-4851-b05c-5bc2afdc93ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute the cross-tabulation (co-occurrence counts)\n",
    "heatmap_data = pd.crosstab(adata.obs['region_annotation'], adata.obs['leiden_gcn_finetuned'])\n",
    "heatmap_data = heatmap_data.div(heatmap_data.sum(axis=1), axis=0)*100\n",
    "heatmap_data = heatmap_data.astype(int)\n",
    "\n",
    "# Step 2: Plot the heatmap\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\"d\", cmap=\"Blues\",ax=ax)\n",
    "ax.set_xlabel('SpatialFusion (finetuned) niches')\n",
    "ax.set_ylabel('Region annotations')\n",
    "ax.set_title('SpatialFusion (finetuned) co-occurrence')\n",
    "fig.savefig('../../../SpatialFusion/results/figures_Fig4/LUAD_SpatialFusion_finetuned_confusion.svg', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a3288-d665-4a74-bdf5-de5fcf5e735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute the cross-tabulation (co-occurrence counts)\n",
    "heatmap_data = pd.crosstab(adata.obs['region_annotation'], adata.obs['leiden_omiclip_image'])\n",
    "heatmap_data = heatmap_data.div(heatmap_data.sum(axis=1), axis=0)*100\n",
    "heatmap_data = heatmap_data.astype(int)\n",
    "\n",
    "# Step 2: Plot the heatmap\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt=\"d\", cmap=\"Blues\",ax=ax)\n",
    "ax.set_xlabel('OmiCLIP image niches')\n",
    "ax.set_ylabel('Region annotations')\n",
    "ax.set_title('OmiCLIP image co-occurrence')\n",
    "fig.savefig('../../../SpatialFusion/results/figures_Fig4/LUAD_OmiCLIP_image_confusion.svg', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf240d9f-a0f3-46ff-b7ce-d7ec32d5f486",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
